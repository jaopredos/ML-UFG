{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Guardar índices e Target para separar depois\n",
    "len_train = len(train)\n",
    "target = train['Transported'].astype(int)\n",
    "passenger_ids = test['PassengerId'].copy()\n",
    "\n",
    "# Remover target do treino para concatenar\n",
    "train_x = train.drop('Transported', axis=1)\n",
    "df = pd.concat([train_x, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset Total: {df.shape}\")\n",
    "\n",
    "# Extrair Grupo do PassengerId \n",
    "df['Group'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "df['GroupSize'] = df['Group'].map(df['Group'].value_counts())\n",
    "\n",
    "# Extrair Cabine (Deck/Num/Side)\n",
    "df['Cabin'] = df['Cabin'].fillna('Z/9999/Z')\n",
    "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "df['Num'] = df['Num'].astype(int)\n",
    "\n",
    "# Voltar nulos originais para 'Z' (ou tratar como Unknown)\n",
    "df.loc[df['Deck']=='Z', 'Deck'] = np.nan\n",
    "df.loc[df['Side']=='Z', 'Side'] = np.nan\n",
    "\n",
    "# Engenharia de Gastos (Consistência CryoSleep)\n",
    "cols_gastos = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Preencher nulos de gastos com 0\n",
    "df[cols_gastos] = df[cols_gastos].fillna(0)\n",
    "\n",
    "# Criar TotalSpend\n",
    "df['TotalSpend'] = df[cols_gastos].sum(axis=1)\n",
    "df['NoSpending'] = (df['TotalSpend'] == 0).astype(int)\n",
    "\n",
    "df.loc[df['TotalSpend'] > 0, 'CryoSleep'] = False\n",
    "\n",
    "# Preencher HomePlanet baseado no Grupo (Pessoas do mesmo grupo vêm do mesmo planeta)\n",
    "group_homeplanet = df.groupby('Group')['HomePlanet'].first() # Pega o primeiro não nulo do grupo\n",
    "df['HomePlanet'] = df['HomePlanet'].fillna(df['Group'].map(group_homeplanet))\n",
    "\n",
    "# O que sobrar de nulo em Categóricas será preenchido como 'Unknown' ou com a Moda\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        # Preenche com a moda\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Preencher Idade com Mediana\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Extrair Sobrenome\n",
    "df['Surname'] = df['Name'].fillna('Unknown Unknown').apply(lambda x: x.split(' ')[-1])\n",
    "df['FamilySize'] = df['Surname'].map(df['Surname'].value_counts())\n",
    "# Se sobrenome for Unknown, FamilySize não é confiável (setar para 0 ou média)\n",
    "df.loc[df['Surname']=='Unknown', 'FamilySize'] = 0\n",
    "\n",
    "# Deck + Side (Mapeia local específico do navio)\n",
    "df['DeckSide'] = df['Deck'].astype(str) + df['Side'].astype(str)\n",
    "\n",
    "# Log Transform dos gastos\n",
    "for col in cols_gastos + ['TotalSpend']:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "# Colunas que vamos usar no modelo\n",
    "# Removemos IDs e textos livres que já foram processados\n",
    "cols_drop = ['PassengerId', 'Name', 'Cabin', 'Group', 'Surname']\n",
    "df_final = df.drop(columns=cols_drop)\n",
    "\n",
    "# Separar de volta em Treino e Teste\n",
    "X_train = df_final.iloc[:len_train].copy()\n",
    "X_test = df_final.iloc[len_train:].copy()\n",
    "y_train = target\n",
    "\n",
    "# Identificar Categóricas para o CatBoost\n",
    "cat_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side', 'DeckSide']\n",
    "\n",
    "# Garantir que são strings\n",
    "for col in cat_features:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "print(\"Dados Processados!\")\n",
    "print(f\"Treino: {X_train.shape} | Teste: {X_test.shape}\")\n",
    "\n",
    "\n",
    "print(\"Iniciando Treinamento CatBoost...\")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Treinar no dataset completo (Full Train) para maximizar aprendizado\n",
    "model.fit(X_train, y_train, cat_features=cat_features)\n",
    "\n",
    "\n",
    "print(\"Gerando previsões...\")\n",
    "predictions = model.predict(X_test)\n",
    "# CatBoost retorna 0 e 1, converter para Bool (True/False)\n",
    "predictions_bool = predictions.astype(bool)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Transported': predictions_bool\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_advanced_eda_catboost.csv', index=False)\n",
    "print(\"Arquivo 'submission_advanced_eda_catboost.csv' gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Total: (12970, 13)\n",
      "Separando Treino e Validação para Early Stopping...\n",
      "Iniciando Treinamento CatBoost Otimizado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Pedro\\AppData\\Local\\Temp\\ipykernel_1664\\2539684284.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(df[col].mode()[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7841386\ttest: 0.7745399\tbest: 0.7745399 (0)\ttotal: 236ms\tremaining: 7m 50s\n",
      "200:\tlearn: 0.8170253\ttest: 0.7898773\tbest: 0.7898773 (200)\ttotal: 13.1s\tremaining: 1m 56s\n",
      "400:\tlearn: 0.8297469\ttest: 0.7983129\tbest: 0.7990798 (393)\ttotal: 27.6s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.8436866\ttest: 0.8044479\tbest: 0.8052147 (591)\ttotal: 39.4s\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.8067484663\n",
      "bestIteration = 674\n",
      "\n",
      "Shrink model to first 675 iterations.\n",
      "Melhor Acurácia na Validação: 0.8067\n",
      "Gerando previsões no Teste...\n",
      "Arquivo 'submission_catboost_improved.csv' gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train = pd.read_csv(r'C:\\Users\\João Pedro\\Documents\\UFG\\AMS\\AS2\\data\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\João Pedro\\Documents\\UFG\\AMS\\AS2\\data\\test.csv')\n",
    "\n",
    "len_train = len(train)\n",
    "target = train['Transported'].astype(int)\n",
    "passenger_ids = test['PassengerId'].copy()\n",
    "\n",
    "train_x = train.drop('Transported', axis=1)\n",
    "df = pd.concat([train_x, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset Total: {df.shape}\")\n",
    "\n",
    "# Extração Básica (Cabin e Grupos) \n",
    "df['Group'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "df['GroupSize'] = df['Group'].map(df['Group'].value_counts())\n",
    "\n",
    "# Usamos -1 para nulos numéricos (árvores lidam bem com isso) e 'Unknown' para texto\n",
    "df['Cabin'] = df['Cabin'].fillna('Unknown/-1/Unknown')\n",
    "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "df['Num'] = pd.to_numeric(df['Num'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "# Engenharia de Gastos \n",
    "cols_gastos = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "df[cols_gastos] = df[cols_gastos].fillna(0)\n",
    "\n",
    "# Features de Estilo de Gastos\n",
    "df['LuxurySpend'] = df['RoomService'] + df['Spa'] + df['VRDeck']\n",
    "df['BasicSpend'] = df['FoodCourt'] + df['ShoppingMall']\n",
    "df['TotalSpend'] = df[cols_gastos].sum(axis=1)\n",
    "df['NoSpending'] = (df['TotalSpend'] == 0).astype(int)\n",
    "\n",
    "# Consistência\n",
    "df.loc[df['TotalSpend'] > 0, 'CryoSleep'] = False\n",
    "df.loc[df['CryoSleep'] == True, cols_gastos] = 0\n",
    "\n",
    "# Imputação Inteligente\n",
    "group_homeplanet = df.groupby('Group')['HomePlanet'].first()\n",
    "df['HomePlanet'] = df['HomePlanet'].fillna(df['Group'].map(group_homeplanet))\n",
    "\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Features Familiares\n",
    "df['Surname'] = df['Name'].fillna('Unknown Unknown').apply(lambda x: x.split(' ')[-1])\n",
    "df['FamilySize'] = df['Surname'].map(df['Surname'].value_counts())\n",
    "df.loc[df['Surname']=='Unknown', 'FamilySize'] = 0\n",
    "\n",
    "df['DeckSide'] = df['Deck'].astype(str) + df['Side'].astype(str)\n",
    "\n",
    "# Cria 10 regiões baseadas na numeração\n",
    "df['CabinRegion'] = pd.qcut(df['Num'].replace(-1, np.nan), q=10, labels=False).fillna(-1).astype(int)\n",
    "\n",
    "# Log Transform dos gastos\n",
    "cols_log = cols_gastos + ['TotalSpend', 'LuxurySpend', 'BasicSpend']\n",
    "for col in cols_log:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "cols_drop = ['PassengerId', 'Name', 'Cabin', 'Group', 'Surname']\n",
    "df_final = df.drop(columns=cols_drop)\n",
    "\n",
    "X = df_final.iloc[:len_train].copy()\n",
    "X_test_final = df_final.iloc[len_train:].copy()\n",
    "y = target\n",
    "\n",
    "# Identificar Categóricas\n",
    "cat_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side', 'DeckSide']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test_final[col] = X_test_final[col].astype(str)\n",
    "\n",
    "print(\"Separando Treino e Validação para Early Stopping...\")\n",
    "\n",
    "# Aqui separamos 15% do treino original para servir de \"fiscal\" do modelo\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Iniciando Treinamento CatBoost Otimizado...\")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.02,     \n",
    "    depth=6,                # Profundidade balanceada\n",
    "    l2_leaf_reg=3.0,        # Regularização padrão\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=200,            # Imprime a cada 200 iterações\n",
    "    random_seed=42,\n",
    "    od_type='Iter',         # Detecção de Overfitting\n",
    "    od_wait=100             # Espera 100 iterações sem melhorar antes de parar\n",
    ")\n",
    "\n",
    "# Treinamos observando o conjunto de validação\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_val, y_val), # O modelo usa isso para saber quando parar\n",
    "    use_best_model=True      # Garante que no final ele volta para a melhor época\n",
    ")\n",
    "\n",
    "print(f\"Melhor Acurácia na Validação: {model.get_best_score()['validation']['Accuracy']:.4f}\")\n",
    "\n",
    "# Previsão\n",
    "print(\"Gerando previsões no Teste...\")\n",
    "predictions = model.predict(X_test_final)\n",
    "predictions_bool = predictions.astype(bool)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Transported': predictions_bool\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_catboost_improved.csv', index=False)\n",
    "print(\"Arquivo 'submission_catboost_improved.csv' gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c81756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Preparando dados para Optuna...\")\n",
    "\n",
    "def objective(trial):\n",
    "    # Definindo o espaço de busca (Hiperparâmetros)\n",
    "    params = {\n",
    "        'iterations': 2000, # Mantemos fixo alto, usamos early_stopping\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 8), # Árvores profundas (>8) costumam overfittar aqui\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10), # Regularização\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 10), # Ajuda a ignorar ruído\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': 254,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'verbose': False,\n",
    "        'random_seed': 42,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 50, # Early Stopping\n",
    "        'cat_features': cat_features # Sua lista de colunas categóricas\n",
    "    }\n",
    "\n",
    "    # Cross-Validation com 5 Folds\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        \n",
    "        # Treina e avalia\n",
    "        model.fit(X_tr, y_tr, \n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  early_stopping_rounds=50, \n",
    "                  verbose=False)\n",
    "        \n",
    "        # Pega a melhor acurácia desse fold\n",
    "        # best_score_ retorna um dicionário, pegamos a validação\n",
    "        best_acc = model.get_best_score()['validation']['Accuracy']\n",
    "        scores.append(best_acc)\n",
    "\n",
    "    # O objetivo é maximizar a MÉDIA das acurácias dos 5 folds\n",
    "    return np.mean(scores)\n",
    "\n",
    "print(\"Iniciando busca com Optuna (Isso pode demorar alguns minutos)...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30) \n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MELHORES PARÂMETROS ENCONTRADOS:\")\n",
    "print(\"=\"*50)\n",
    "print(study.best_params)\n",
    "print(f\"Melhor Acurácia Média (CV): {study.best_value:.5f}\")\n",
    "\n",
    "# Treinar o modelo final com os melhores parâmetros\n",
    "print(\"\\nTreinando modelo final com os parâmetros vencedores...\")\n",
    "\n",
    "# Pegar os melhores parâmetros\n",
    "final_params = study.best_params\n",
    "final_params['iterations'] = 2500 # Aumentamos um pouco para o treino final total\n",
    "final_params['cat_features'] = cat_features\n",
    "final_params['verbose'] = 100\n",
    "final_params['od_wait'] = 100\n",
    "\n",
    "# Treinar no Dataset completo\n",
    "model_final = CatBoostClassifier(**final_params)\n",
    "model_final.fit(X_train, y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando previsões...\n",
      "Arquivo 'submission_catboost_optuna_v2.csv' gerado! Boa sorte!\n"
     ]
    }
   ],
   "source": [
    "# Prever\n",
    "print(\"Gerando previsões...\")\n",
    "predictions = model_final.predict(X_test_final) \n",
    "predictions_bool = predictions.astype(bool)\n",
    "\n",
    "# Salvar\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids, \n",
    "    'Transported': predictions_bool\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_catboost_optuna_v2.csv', index=False)\n",
    "print(\"Arquivo 'submission_catboost_optuna_v2.csv' gerado! Boa sorte!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
